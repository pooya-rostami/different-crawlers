{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "from datetime import datetime\n",
    "import time\n",
    "import sys\n",
    "import json\n",
    "import os.path\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_root = \"https://api.github.com\"\n",
    "request_header = {'Accept':'application/vnd.github.v3+json'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"list of all client_id and client_secret that we have\"\"\"\n",
    "client_list = [('client_id', 'client_secret')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_commits(request_subject, df, client_list, client_number=0,request_header=request_header, upper_bound=math.inf, page_number=1):\n",
    "    while(page_number<=upper_bound):\n",
    "        try: \n",
    "            response = requests.get(request_subject + '/issues?state=all&per_page=100&page=' + str(page_number) + \n",
    "                                    '&client_id=' + client_list[client_number][0] + '&client_secret=' + client_list[client_number][1], headers = request_header)\n",
    "            if response.ok:\n",
    "                json_response = response.json()\n",
    "                if not json_response:\n",
    "                    break\n",
    "                for i in range(len(json_response)):\n",
    "                    \"\"\" for each issue we create a dictionary to keep data of that issue\n",
    "                    these try/excepts add data to this dictionary and i the end we add this dictioary to main data frame \n",
    "                    which holds whole data about this specific peoject \"\"\"\n",
    "                    data = {}\n",
    "                    try:\n",
    "                        data['id'] = json_response[i]['id']\n",
    "                    except:\n",
    "                        data['id'] = \"\"\n",
    "                    try:\n",
    "                        data['node_id'] = json_response[i]['node_id']\n",
    "                    except:\n",
    "                        data['node_id'] = \"\"\n",
    "                    try:\n",
    "                        data['number'] = json_response[i]['number']\n",
    "                    except:\n",
    "                        data['number'] = \"\"\n",
    "                    try:\n",
    "                        data['title'] = json_response[i]['title']\n",
    "                    except:\n",
    "                        data['title'] = \"\"\n",
    "                    try:\n",
    "                        data['user_login_name'] = json_response[i]['user']['login']   \n",
    "                    except:\n",
    "                        data['user_login_name'] = \"\"\n",
    "                    try:\n",
    "                        data['user_login_id'] = json_response[i]['user']['id']\n",
    "                    except:\n",
    "                        data['user_login_id'] = \"\"\n",
    "                    try:\n",
    "                        data['user_node_id'] = json_response[i]['user']['node_id']    \n",
    "                    except:\n",
    "                        data['user_node_id'] = \"\"\n",
    "                    try:\n",
    "                        data['user_type'] = json_response[i]['user']['type']    \n",
    "                    except:\n",
    "                        data['user_type'] = \"\"\n",
    "                    try:\n",
    "                        data['body'] = json_response[i]['body']    \n",
    "                    except:\n",
    "                        data['body'] = \"\"\n",
    "                    try:\n",
    "                        data['labels'] = json_response[i]['labels'] \n",
    "                    except: \n",
    "                        data['labels'] = \"\"\n",
    "                    try:\n",
    "                        data['state'] = json_response[i]['state']   \n",
    "                    except:\n",
    "                        data['state'] = \"\"\n",
    "                    try:    \n",
    "                        tmp = ''\n",
    "                        num_of_assignees = len(json_response[i]['assignees']) \n",
    "                        for j in range(num_of_assignees):\n",
    "                            assignee = json_response[i]['assignees'][j]\n",
    "                            tmp += ('login_name:'+assignee['login'])\n",
    "                            tmp += ('login_id:'+assignee['id'])\n",
    "                            tmp += ('login_node_id:'+assignee['node_id'])\n",
    "                            tmp += ('login_type:'+assignee['type'])\n",
    "                            if j < (num_of_assignees-1):\n",
    "                                tmp += '|'\n",
    "                        data['assignees']= tmp\n",
    "                    except:\n",
    "                        data['assignees'] = \"\"\n",
    "                    try:\n",
    "                        data['created_at'] = json_response[i]['created_at']\n",
    "                    except:\n",
    "                        data['created_at'] = \"\"\n",
    "                    try:\n",
    "                        data['closed_at'] = json_response[i]['closed_at']\n",
    "                    except:\n",
    "                        data['closed_at'] = \"\"\n",
    "\n",
    "                    df = df.append(data, ignore_index=True)\n",
    "                print(f'page {page_number} is added to data frame')\n",
    "                page_number += 1\n",
    "                try:\n",
    "                    if int(response.headers[\"X-RateLimit-Remaining\"]) < 2:\n",
    "                        print(\"limit exceeded!!!!!!!!!!!!\")\n",
    "                        delay = 60\n",
    "                        print('sleeping for '+str(delay)+' seconds...')\n",
    "                        print(\"current time:\" + str(datetime.now()))\n",
    "                        time.sleep(int(delay))\n",
    "                except (KeyError):\n",
    "                    pass\n",
    "            else:\n",
    "                \"\"\" this part is for the time our client limit is complete so we change it by changing the client number \"\"\"\n",
    "                resp = json.loads(response.text or response.content)\n",
    "                print('\\n---'+str(response))\n",
    "                print('\\n---'+str(resp['message']))\n",
    "                new_client_number = client_number + 1\n",
    "                new_client_number %= int(len(client_list))\n",
    "                if new_client_number < int(len(client_list)):\n",
    "                    return get_commits(request_subject, df, client_list, client_number=new_client_number, page_number=page_number)\n",
    "                else:\n",
    "                    return df \n",
    "        except requests.exceptions.Timeout as e:\n",
    "            print(\"-------timeout-------\")\n",
    "            print(e)\n",
    "            time.sleep(delay_conn)\n",
    "            return get_commits(request_subject, df, request_header, upper_bound, page_number)\n",
    "        except requests.ConnectionError as e:\n",
    "            print(\"-------connection error-------\")\n",
    "            print(e)\n",
    "            time.sleep(delay_conn)\n",
    "            return get_commits(request_subject, df, request_header, upper_bound, page_number)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" we create a base url with repo and owner name, also create base dataframe which store data \n",
    "and in the end save the data we get from 'get_commits' function which are all the commits of that specific project \"\"\"\n",
    "def get_commits_of_repo(owner, repo, client_list, api_root=api_root):\n",
    "    request_subject = api_root + '/repos/' + owner + '/' + repo \n",
    "    cols = ['id', 'node_id', 'number', 'title', 'user_login_name', 'user_login_id', 'user_node_id', 'body', \n",
    "            'labels','state', 'assignees', 'created_at', 'closed_at', 'user_type']\n",
    "    df = pd.DataFrame(columns=cols)\n",
    "    repo_dataframe = get_commits(request_subject, df, client_list=client_list)\n",
    "    print(f'data frame shape is : {repo_dataframe.shape}')\n",
    "    repo_dataframe.to_csv(owner+'_'+repo+'_issues_data.csv', index=False)\n",
    "    print(f\"issues for {owner}/{repo} saved succesfully!!! ;)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" specifying all the owners and repos that we want their whole commits data \"\"\"\n",
    "sources = [('owner','repo')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for source in sources:\n",
    "    if not os.path.exists(source[0]+'_'+source[1]+'_issues_data.csv'):\n",
    "        print(f'getting issues for {source[0]}/{source[1]} is started')\n",
    "        get_commits_of_repo(source[0], source[1], client_list, api_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
