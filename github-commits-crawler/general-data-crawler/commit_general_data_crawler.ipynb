{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "from datetime import datetime\n",
    "import time\n",
    "import sys\n",
    "import json\n",
    "import os.path\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_header = {'Accept':'application/vnd.github.v3+json'}\n",
    "api_root = \"https://api.github.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"list of all client_id and client_secret that we have\"\"\"\n",
    "client_list = [('client_id', 'client_secret')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_commits(request_subject, df, client_list, client_number=0,request_header=request_header, upper_bound=math.inf, page_number=1):\n",
    "    while(page_number<=upper_bound):\n",
    "        try: \n",
    "            response = requests.get(request_subject + '/commits?per_page=100&page=' + str(page_number) + \n",
    "                                    '&client_id=' + client_list[client_number][0] + '&client_secret=' + client_list[client_number][1], headers = request_header)\n",
    "            if response.ok:\n",
    "                json_response = response.json()\n",
    "                if not json_response:\n",
    "                    break\n",
    "                for i in range(len(json_response)):\n",
    "                    \"\"\" for each commit we create a dictionary to keep data of that commit\n",
    "                    these try/excepts add data to this dictionary and i the end we add this dictioary to main data frame \n",
    "                    which holds whole data about this specific peoject \"\"\"\n",
    "                    data = {}\n",
    "                    data['sha'] = json_response[i]['sha']\n",
    "                    try:\n",
    "                        data['commit_author_name'] = json_response[i]['commit']['author']['name']\n",
    "                    except:\n",
    "                        data['commit_author_name'] = \"\"\n",
    "                    try:\n",
    "                        data['commit_author_email'] = json_response[i]['commit']['author']['email']\n",
    "                    except:\n",
    "                        data['commit_author_email'] = \"\"\n",
    "                    try:\n",
    "                        data['commit_author_date'] = json_response[i]['commit']['author']['date']\n",
    "                    except:\n",
    "                        data['commit_author_date'] = \"\"\n",
    "                    try:\n",
    "                        data['commit_message'] = json_response[i]['commit']['message']\n",
    "                    except:\n",
    "                        data['commit_message'] = \"\"\n",
    "                    try:\n",
    "                        data['author_login'] = json_response[i]['author']['login']   \n",
    "                    except:\n",
    "                        data['author_login'] = \"\"\n",
    "                    try:\n",
    "                        data['author_id'] = json_response[i]['author']['id']\n",
    "                    except:\n",
    "                        data['author_id'] = \"\"\n",
    "                    try:\n",
    "                        data['author_node_id'] = json_response[i]['author']['node_id']    \n",
    "                    except:\n",
    "                        data['author_node_id'] = \"\"\n",
    "                    try:\n",
    "                        data['author_type'] = json_response[i]['author']['type']\n",
    "                    except:\n",
    "                        data['author_type'] = \"\"\n",
    "                    try:\n",
    "                        data['committer_login'] = json_response[i]['committer']['login']    \n",
    "                    except:\n",
    "                        data['committer_login'] = \"\"\n",
    "                    try:\n",
    "                        data['committer_id'] = json_response[i]['committer']['id']    \n",
    "                    except: \n",
    "                        data['committer_id'] = \"\"\n",
    "                    try:\n",
    "                        data['committer_date'] = json_response[i]['committer']['date']    \n",
    "                    except: \n",
    "                        data['committer_date'] = \"\"\n",
    "                    try:\n",
    "                        data['committer_node_id'] = json_response[i]['committer']['node_id']    \n",
    "                    except:\n",
    "                        data['committer_node_id'] = \"\"\n",
    "                    try:    \n",
    "                        data['verification_verified']= json_response[i]['commit']['verification']['verified']\n",
    "                    except:\n",
    "                        data['verification_verified'] = \"\"\n",
    "                    try:\n",
    "                        data['verification_reason'] = json_response[i]['commit']['verification']['reason']\n",
    "                    except:\n",
    "                        data['verification_reason'] = \"\"\n",
    "                    try:\n",
    "                        data['stats_additions'] = json_response[i]['stats']['additions']\n",
    "                    except:\n",
    "                        data['stats_additions'] = \"\"\n",
    "                    try:\n",
    "                        data['stats_deletions'] = json_response[i]['stats']['deletions']\n",
    "                    except:\n",
    "                        data['stats_deletions'] = \"\"\n",
    "                    try:\n",
    "                        data['stats_total'] = json_response[i]['stats']['total']\n",
    "                    except:\n",
    "                        data['stats_total'] = \"\"\n",
    "\n",
    "                    df = df.append(data, ignore_index=True)\n",
    "                print(f'page {page_number} is added to data frame')\n",
    "                page_number += 1\n",
    "                try:\n",
    "                    if int(response.headers[\"X-RateLimit-Remaining\"]) < 2:\n",
    "                        print(\"limit exceeded!!!!!!!!!!!!\")\n",
    "                        delay = 60\n",
    "                        print('sleeping for '+str(delay)+' seconds...')\n",
    "                        print(\"current time:\" + str(datetime.now()))\n",
    "                        time.sleep(int(delay))\n",
    "                except (KeyError):\n",
    "                    pass\n",
    "            else:\n",
    "                \"\"\" this part is for the time our client limit is complete so we change it by changing the client number \"\"\"\n",
    "                resp = json.loads(response.text or response.content)\n",
    "                print('\\n---'+str(response))\n",
    "                print('\\n---'+str(resp['message']))\n",
    "                new_client_number = client_number + 1\n",
    "                new_client_number %= int(len(client_list))\n",
    "                if new_client_number < int(len(client_list)):\n",
    "                    return get_commits(request_subject, df, client_list, client_number=new_client_number, page_number=page_number)\n",
    "                else:\n",
    "                    return df \n",
    "        except requests.exceptions.Timeout as e:\n",
    "            print(\"-------timeout-------\")\n",
    "            print(e)\n",
    "            time.sleep(delay_conn)\n",
    "            return get_commits(request_subject, df, request_header, upper_bound, page_number)\n",
    "        except requests.ConnectionError as e:\n",
    "            print(\"-------connection error-------\")\n",
    "            print(e)\n",
    "            time.sleep(delay_conn)\n",
    "            return get_commits(request_subject, df, request_header, upper_bound, page_number)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" we create a base url with repo and owner name, also create base dataframe which store data \n",
    "and in the end save the data we get from 'get_commits' function which are all the commits of that specific project \"\"\"\n",
    "def get_commits_of_repo(owner, repo, client_list, api_root=api_root):\n",
    "    request_subject = api_root + '/repos/' + owner + '/' + repo \n",
    "    # creating the suitable data frame\n",
    "    cols = ['sha', 'commit_author_name', 'commit_author_email', 'commit_message', 'author_login', 'author_id', 'author_node_id', \n",
    "            'committer_login', 'committer_id', 'committer_date', 'committer_node_id', 'verification_verified', 'verification_reason', 'changed_files_name', \n",
    "            'changed_codes', 'comments_bodies', 'comments_creation_date', 'comment_updating_date', 'comment_users_login', 'comment_users_id', 'author_type',\n",
    "            'stats_additions', 'stats_deletions', 'stats_total']\n",
    "    df = pd.DataFrame(columns=cols)\n",
    "    df['changed_files_name'] = df['changed_files_name'].astype(object)\n",
    "    df['changed_codes'] = df['changed_codes'].astype(object)\n",
    "    df['comments_bodies'] = df['comments_bodies'].astype(object)\n",
    "    df['comments_creation_date'] = df['comments_creation_date'].astype(object)\n",
    "    df['comment_updating_date'] = df['comment_updating_date'].astype(object)\n",
    "    df['comment_users_login'] = df['comment_users_login'].astype(object)\n",
    "    df['comment_users_id'] = df['comment_users_id'].astype(object)\n",
    "    # end of creating data frame\n",
    "    repo_dataframe = get_commits(request_subject, df, client_list=client_list)\n",
    "    print(f'data frame shape is : {repo_dataframe.shape}')\n",
    "    repo_dataframe.to_csv(owner+'_'+repo+'_commits_data.csv', index=False)\n",
    "    print(f\"commits for {owner}/{repo} saved succesfully!!! ;)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" specifying all the owners and repos that we want their whole commits data \"\"\"\n",
    "sources = [('owner','repo')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for source in sources:\n",
    "    if not os.path.exists(source[0]+'_'+source[1]+'_commits_data.csv'):\n",
    "        print(f'getting commits for {source[0]}/{source[1]} is started')\n",
    "        get_commits_of_repo(source[0], source[1], client_list, api_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
