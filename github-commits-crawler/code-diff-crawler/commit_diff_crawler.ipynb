{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "from datetime import datetime\n",
    "import time\n",
    "import sys\n",
    "import json\n",
    "import os.path\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_header = {'Accept':'application/vnd.github.v3+json'}\n",
    "api_root = \"https://api.github.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"list of all client_id and client_secret that we have\"\"\"\n",
    "client_list = [('client_id', 'client_secret')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_commits(request_subject, df, client_list, client_number=0,request_header=request_header, upper_bound=math.inf, page_number=1):\n",
    "#     page_number = 1\n",
    "    while(page_number<=upper_bound):\n",
    "        try: \n",
    "            response = requests.get(request_subject + '/commits?per_page=100&page=' + str(page_number) + \n",
    "                                    '&client_id=' + client_list[client_number][0] + '&client_secret=' + client_list[client_number][1], headers = request_header)\n",
    "            if response.ok:\n",
    "                json_response = response.json()\n",
    "                if not json_response:\n",
    "                    break\n",
    "                for i in range(len(json_response)):\n",
    "                    \"\"\" for each commit we create a dictionary to keep data of that commit\n",
    "                    these try/excepts add data to this dictionary and i the end we add this dictioary to main data frame \n",
    "                    which holds whole data about this specific peoject \"\"\"\n",
    "                    data = {}\n",
    "                    data['sha'] = json_response[i]['sha']\n",
    "                    \n",
    "                    \"\"\" for these two data which are commit diff and commit comments we need to send another request to \n",
    "                    get the data from. for commit diff we use 'url' and for comments we use 'comments_url' also becuase of limitation of\n",
    "                    request we have to add these else just in case request response wasn't ok \"\"\"\n",
    "                    try:\n",
    "                        commit_changes = requests.get(json_response[i]['url']+'?client_id=' + client_list[client_number][0] \n",
    "                                                      + '&client_secret=' + client_list[client_number][1], headers = request_header)\n",
    "                        commit_data = commit_changes.json()\n",
    "                        changed_files_name = []\n",
    "                        changed_codes = []\n",
    "                        for j in range(len(commit_data['files'])):\n",
    "                            changed_files_name.append(commit_data['files'][j]['filename'])\n",
    "                            changed_codes.append(commit_data['files'][j]['patch'])\n",
    "                        data['changed_files_name'] = changed_files_name\n",
    "                        data['changed_codes'] = changed_codes\n",
    "\n",
    "                    except:\n",
    "                        data['changed_files_name'] = ''\n",
    "                        data['changed_codes'] = ''\n",
    "                    df = df.append(data, ignore_index=True)\n",
    "                print(f'page {page_number} is added to data frame')\n",
    "                page_number += 1\n",
    "                try:\n",
    "                    if int(response.headers[\"X-RateLimit-Remaining\"]) < 2:\n",
    "                        print(\"limit exceeded!!!!!!!!!!!!\")\n",
    "                        delay = 60\n",
    "                        print('sleeping for '+str(delay)+' seconds...')\n",
    "                        print(\"current time:\" + str(datetime.now()))\n",
    "                        time.sleep(int(delay))\n",
    "                except (KeyError):\n",
    "                    pass\n",
    "            else:\n",
    "                \"\"\" this part is for the time our client limit is complete so we change it by changing the client number \"\"\"\n",
    "                resp = json.loads(response.text or response.content)\n",
    "                print('\\n---'+str(response))\n",
    "                print('\\n---'+str(resp['message']))\n",
    "                new_client_number = client_number + 1\n",
    "                new_client_number %= int(len(client_list))\n",
    "                if new_client_number < int(len(client_list)):\n",
    "                    return get_commits(request_subject, df, client_list, client_number=new_client_number, page_number=page_number)\n",
    "                else:\n",
    "                    return df \n",
    "        except requests.exceptions.Timeout as e:\n",
    "            print(\"-------timeout-------\")\n",
    "            print(e)\n",
    "            time.sleep(delay_conn)\n",
    "            return get_commits(request_subject, df, request_header, upper_bound, page_number)\n",
    "        except requests.ConnectionError as e:\n",
    "            print(\"-------connection error-------\")\n",
    "            print(e)\n",
    "            time.sleep(delay_conn)\n",
    "            return get_commits(request_subject, df, request_header, upper_bound, page_number)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" we create a base url with repo and owner name, also create base dataframe which store data \n",
    "and in the end save the data we get from 'get_commits' function which are all the commits of that specific project \"\"\"\n",
    "def get_commits_of_repo(owner, repo, client_list, api_root=api_root):\n",
    "    request_subject = api_root + '/repos/' + owner + '/' + repo \n",
    "    # creating the suitable data frame\n",
    "    cols = ['sha', 'changed_files_name', 'changed_codes']\n",
    "    df = pd.DataFrame(columns=cols)\n",
    "    df['changed_files_name'] = df['changed_files_name'].astype(object)\n",
    "    df['changed_codes'] = df['changed_codes'].astype(object)\n",
    "    \n",
    "    # end of creating data frame\n",
    "    repo_dataframe = get_commits(request_subject, df, client_list=client_list)\n",
    "    print(f'data frame shape is : {repo_dataframe.shape}')\n",
    "    repo_dataframe.to_csv(owner+'_'+repo+'_commits_code_diff_data.csv', index=False)\n",
    "    print(f\"commits for {owner}/{repo} saved succesfully!!! ;)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" specifying all the owners and repos that we want their whole commits data \"\"\"\n",
    "sources = [('owner','repo')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for source in sources:\n",
    "    if not os.path.exists(source[0]+'_'+source[1]+'_commits_code_diff_data.csv'):\n",
    "        print(f'getting commits for {source[0]}/{source[1]} is started')\n",
    "        get_commits_of_repo(source[0], source[1], client_list, api_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
